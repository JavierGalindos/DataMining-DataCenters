varianceScaled <- PCA$varianceExplained / sum(PCA$varianceExplained)
# Obtain k components for specific variability
k <- length(varianceScaled[cumsum(varianceScaled)<= varianceExplained])
dataProjected <- dataset %*% PCA$components[,1:k]
return (dataProjected)
}
# Generating dataset
nCol <- 4
dataset <- matrix(rnorm(nCol* 500),ncol= nCol)
dataset=cbind(dataset,dataset[,1]*runif(500)*0.01)
dataset=cbind(dataset,dataset[,2]*runif(500)*0.01)
dataset=cbind(dataset,dataset[,3]*runif(500)*0.01)
#dataset=cbind(dataset,dataset[,4]*runif(500)*0.01)
cor(dataset)
# PCA
PCA <- JG_pca(dataset)
varianceScaled <- PCA$varianceExplained / sum(PCA$varianceExplained)
barplot(varianceScaled, main = 'Variance explained', xlab = 'Features', ylab = 'Variance explained', col = 'indianred', ylim=c(0,0.35))
# Project data
k <- 7
dataProjected <- dataset %*% PCA$components[,1:k]
cor(dataProjected)
# Generating dataset
nCol <- 4
dataset <- matrix(rnorm(nCol* 500),ncol= nCol)
dataset=cbind(dataset,dataset[,1]^2*cos(dataset[,1]))
dataset=cbind(dataset,dataset[,3]^2)
dataset=cbind(dataset,dataset[,4]^2)
# Correlation matrix
cor(dataset)
# PCA
PCA <- JG_pca(dataset)
varianceScaled <- PCA$varianceExplained / sum(PCA$varianceExplained)
k <- length(varianceScaled[cumsum(varianceScaled)<= 0.95])
barplot(varianceScaled, main = 'Variance explained', xlab = 'Features', ylab = 'Variance explained', col = 'indianred')
# Project data
k <- 6
dataProjected <- dataset %*% PCA$components[,1:k]
# Correlation matrix
cor(dataProjected)
# Generating dataset
nCol <- 4
dataset <- matrix(rnorm(nCol* 500),ncol= nCol)
dataset=cbind(dataset,dataset[,1]^2)
dataset=cbind(dataset,dataset[,3]^2)
dataset=cbind(dataset,dataset[,4]^2)
# Correlation matrix
cor(dataset)
# PCA
PCA <- JG_pca(dataset)
varianceScaled <- PCA$varianceExplained / sum(PCA$varianceExplained)
k <- length(varianceScaled[cumsum(varianceScaled)<= 0.95])
barplot(varianceScaled, main = 'Variance explained', xlab = 'Features', ylab = 'Variance explained', col = 'indianred')
# Project data
k <- 6
dataProjected <- dataset %*% PCA$components[,1:k]
# Correlation matrix
cor(dataProjected)
# Generating dataset
nCol <- 4
dataset <- matrix(rnorm(nCol* 500),ncol= nCol)
dataset=cbind(dataset,dataset[,1]^2*cos(dataset[,1]))
dataset=cbind(dataset,dataset[,1]^2*sin(dataset[,1]))
dataset=cbind(dataset,dataset[,1]^2*tanh(dataset[,1]))
# Correlation matrix
cor(dataset)
# PCA
PCA <- JG_pca(dataset)
varianceScaled <- PCA$varianceExplained / sum(PCA$varianceExplained)
k <- length(varianceScaled[cumsum(varianceScaled)<= 0.95])
barplot(varianceScaled, main = 'Variance explained', xlab = 'Features', ylab = 'Variance explained', col = 'indianred')
# Project data
k <- 6
dataProjected <- dataset %*% PCA$components[,1:k]
# Correlation matrix
cor(dataProjected)
# Generating dataset
nCol <- 4
dataset <- matrix(rnorm(nCol* 500),ncol= nCol)
dataset=cbind(dataset,dataset[,1]^2*cos(dataset[,1]))
dataset=cbind(dataset,dataset[,1]^2*sin(dataset[,1]))
dataset=cbind(dataset,dataset[,1]^2*tanh(dataset[,2]))
# Correlation matrix
cor(dataset)
# PCA
PCA <- JG_pca(dataset)
varianceScaled <- PCA$varianceExplained / sum(PCA$varianceExplained)
k <- length(varianceScaled[cumsum(varianceScaled)<= 0.95])
barplot(varianceScaled, main = 'Variance explained', xlab = 'Features', ylab = 'Variance explained', col = 'indianred')
# Project data
k <- 6
dataProjected <- dataset %*% PCA$components[,1:k]
# Correlation matrix
cor(dataProjected)
set.seed(1337)
# PCA
JG_pca <- function(dataset){
mu <- colMeans(dataset)
data_centered <- matrix(, nrow= nrow(dataset), ncol = ncol(dataset))
for (i in seq(1:ncol(dataset))){
data_centered[,i] <- dataset[,i]- mu[i]  # center the data
}
C <- cov(data_centered)  # describe each axis variation
eigenObject <- eigen(C)
eigenVectors <- eigenObject$vectors
eigenValues <- eigenObject$values
return(list(components = eigenVectors, varianceExplained = eigenValues))
}
JG_pca_project <- function(dataset, varianceExplained){
PCA <- JG_pca(dataset)
varianceScaled <- PCA$varianceExplained / sum(PCA$varianceExplained)
# Obtain k components for specific variability
k <- length(varianceScaled[cumsum(varianceScaled)<= varianceExplained])
dataProjected <- dataset %*% PCA$components[,1:k]
return (dataProjected)
}
# Generating dataset
nCol <- 4
dataset <- matrix(rnorm(nCol* 500),ncol= nCol)
# Generating dataset
nCol <- 4
dataset <- matrix(rnorm(nCol* 500),ncol= nCol)
dataset=cbind(dataset,dataset[,1]^2*cos(dataset[,1]))
dataset=cbind(dataset,dataset[,1]^2*sin(dataset[,1]))
dataset=cbind(dataset,dataset[,1]^2*tanh(dataset[,2]))
# Correlation matrix
cor(dataset)
# Generating dataset
nCol <- 5
dataset <- matrix(rnorm(nCol* 500),ncol= nCol)
dataset=cbind(dataset,dataset[,1]^2*cos(dataset[,1]))
dataset=cbind(dataset,dataset[,1]^2*sin(dataset[,1]))
dataset=cbind(dataset,dataset[,1]^2*tanh(dataset[,2]))
# Correlation matrix
cor(dataset)
# PCA
PCA <- JG_pca(dataset)
varianceScaled <- PCA$varianceExplained / sum(PCA$varianceExplained)
k <- length(varianceScaled[cumsum(varianceScaled)<= 0.95])
barplot(varianceScaled, main = 'Variance explained', xlab = 'Features', ylab = 'Variance explained', col = 'indianred')
# Project data
k <- 8
dataProjected <- dataset %*% PCA$components[,1:k]
# Correlation matrix
cor(dataProjected)
?scale
# Exercise 4: Data preparation
# Javier Galindos
rm(list=ls())
library("rstudioapi")
set.seed(1337)
# PCA
JG_pca <- function(dataset){
dataset <- scale(dataset, center = FALSE, scale = TRUE)
mu <- colMeans(dataset)
data_centered <- matrix(, nrow= nrow(dataset), ncol = ncol(dataset))
for (i in seq(1:ncol(dataset))){
data_centered[,i] <- dataset[,i]- mu[i]  # center the data
}
C <- cov(data_centered)  # describe each axis variation
eigenObject <- eigen(C)
eigenVectors <- eigenObject$vectors
eigenValues <- eigenObject$values
return(list(components = eigenVectors, varianceExplained = eigenValues))
}
JG_pca_project <- function(dataset, varianceExplained){
PCA <- JG_pca(dataset)
varianceScaled <- PCA$varianceExplained / sum(PCA$varianceExplained)
# Obtain k components for specific variability
k <- length(varianceScaled[cumsum(varianceScaled)<= varianceExplained])
dataProjected <- dataset %*% PCA$components[,1:k]
return (dataProjected)
}
# Generating dataset
nCol <- 4
dataset <- matrix(rnorm(nCol* 500),ncol= nCol)
dataset=cbind(dataset,dataset[,1]*runif(500)*0.01)
dataset=cbind(dataset,dataset[,2]*runif(500)*0.01)
dataset=cbind(dataset,dataset[,3]*runif(500)*0.01)
#dataset=cbind(dataset,dataset[,4]*runif(500)*0.01)
cor(dataset)
# PCA
PCA <- JG_pca(dataset)
varianceScaled <- PCA$varianceExplained / sum(PCA$varianceExplained)
barplot(varianceScaled, main = 'Variance explained', xlab = 'Features', ylab = 'Variance explained', col = 'indianred', ylim=c(0,0.35))
# Project data
k <- 7
dataProjected <- dataset %*% PCA$components[,1:k]
cor(dataProjected)
# Generating dataset
nCol <- 5
dataset <- matrix(rnorm(nCol* 500),ncol= nCol)
dataset=cbind(dataset,dataset[,1]^2*cos(dataset[,1]))
dataset=cbind(dataset,dataset[,1]^2*sin(dataset[,1]))
dataset=cbind(dataset,dataset[,1]^2*tanh(dataset[,2]))
# Correlation matrix
cor(dataset)
# PCA
PCA <- JG_pca(dataset)
varianceScaled <- PCA$varianceExplained / sum(PCA$varianceExplained)
k <- length(varianceScaled[cumsum(varianceScaled)<= 0.95])
barplot(varianceScaled, main = 'Variance explained', xlab = 'Features', ylab = 'Variance explained', col = 'indianred')
# Project data
k <- 8
dataProjected <- dataset %*% PCA$components[,1:k]
# Correlation matrix
cor(dataProjected)
# Generating dataset
nCol <- 5
dataset <- matrix(rnorm(nCol* 500),ncol= nCol)
dataset=cbind(dataset,dataset[,1]^2*cos(dataset[,1]))
dataset=cbind(dataset,dataset[,1]^2*sin(dataset[,1]))
dataset=cbind(dataset,dataset[,1]^2*tanh(dataset[,2]))
# Correlation matrix
cor(dataset)
# PCA
PCA <- JG_pca(dataset)
varianceScaled <- PCA$varianceExplained / sum(PCA$varianceExplained)
k <- length(varianceScaled[cumsum(varianceScaled)<= 0.95])
barplot(varianceScaled, main = 'Variance explained', xlab = 'Features', ylab = 'Variance explained', col = 'indianred')
# Project data
k <- 8
dataProjected <- dataset %*% PCA$components[,1:k]
# Correlation matrix
cor(dataProjected)
# Generating dataset
nCol <- 4
dataset <- matrix(rnorm(nCol* 500),ncol= nCol)
dataset=cbind(dataset,dataset[,1]^2)
dataset=cbind(dataset,dataset[,2]^2)
dataset=cbind(dataset,dataset[,4]^2)
# Correlation matrix
cor(dataset)
# PCA
PCA <- JG_pca(dataset)
varianceScaled <- PCA$varianceExplained / sum(PCA$varianceExplained)
k <- length(varianceScaled[cumsum(varianceScaled)<= 0.95])
barplot(varianceScaled, main = 'Variance explained', xlab = 'Features', ylab = 'Variance explained', col = 'indianred')
# Project data
k <- 7
dataProjected <- dataset %*% PCA$components[,1:k]
# Correlation matrix
cor(dataProjected)
View(dataset)
View(dataset)
nCol <- 4
dataset <- matrix(rnorm(nCol* 500),ncol= nCol)
# Dependent variables
dataset=cbind(dataset,dataset[,1]^2)
dataset=cbind(dataset,dataset[,2]^2)
dataset=cbind(dataset,dataset[,4]^2)
# PCA
PCA <- JG_pca(dataset)
varianceScaled <- PCA$varianceExplained / sum(PCA$varianceExplained)
k <- length(varianceScaled[cumsum(varianceScaled)<= 0.95])
barplot(varianceScaled, main = 'Variance explained', xlab = 'Features', ylab = 'Variance explained', col = 'indianred')
# Exercise 4: Data preparation
# Javier Galindos
rm(list=ls())
library("rstudioapi")
set.seed(123)
# PCA
JG_pca <- function(dataset){
dataset <- scale(dataset, center = FALSE, scale = TRUE)
mu <- colMeans(dataset)
data_centered <- matrix(, nrow= nrow(dataset), ncol = ncol(dataset))
for (i in seq(1:ncol(dataset))){
data_centered[,i] <- dataset[,i]- mu[i]  # center the data
}
C <- cov(data_centered)  # describe each axis variation
eigenObject <- eigen(C)
eigenVectors <- eigenObject$vectors
eigenValues <- eigenObject$values
return(list(components = eigenVectors, varianceExplained = eigenValues))
}
JG_pca_project <- function(dataset, varianceExplained){
PCA <- JG_pca(dataset)
varianceScaled <- PCA$varianceExplained / sum(PCA$varianceExplained)
# Obtain k components for specific variability
k <- length(varianceScaled[cumsum(varianceScaled)<= varianceExplained])
dataProjected <- dataset %*% PCA$components[,1:k]
return (dataProjected)
}
# Generating dataset
# Independent variables
nCol <- 4
dataset <- matrix(rnorm(nCol* 500),ncol= nCol)
# Dependent variables
dataset=cbind(dataset,dataset[,1]^2)
dataset=cbind(dataset,dataset[,2]^2)
dataset=cbind(dataset,dataset[,4]^2)
# Correlation matrix before PCA
cor(dataset)
# PCA
PCA <- JG_pca(dataset)
varianceScaled <- PCA$varianceExplained / sum(PCA$varianceExplained)
k <- length(varianceScaled[cumsum(varianceScaled)<= 0.95])
barplot(varianceScaled, main = 'Variance explained', xlab = 'Features', ylab = 'Variance explained', col = 'indianred')
# ARIMA model for forecast and outliers
rm(list = ls()) # Remove all the objects we created so far.
set.seed(123)
#Libraries
library("rstudioapi")
library(dplyr) # Manipulate data
library(ggplot2) # Plots
library(forecast) # Time series
library(tseries) # Time series
dataDir <- file.path(curDir,"fastStorage") # Concatenate paths
setwd(dataDir)
# Set working directory
curDir <- dirname(getActiveDocumentContext()$path)# Current directory
getwd()
#create a list of the files from your target directory
file_list <- list.files(path=dataDir)
# Load dataset (for loop to load everything)
VM <- read.csv(file = file_list[31], header = TRUE, sep = ";")
# Selecting relevant variables
VM <- VM  %>% select(Timestamp..ms.,CPU.usage....,Memory.usage..KB.,Memory.capacity.provisioned..KB.)
# ARIMA model for forecast and outliers
rm(list = ls()) # Remove all the objects we created so far.
set.seed(123)
#Libraries
library("rstudioapi")
library(dplyr) # Manipulate data
library(ggplot2) # Plots
library(forecast) # Time series
library(tseries) # Time series
# Set working directory
curDir <- dirname(getActiveDocumentContext()$path)# Current directory
dataDir <- file.path(curDir,"fastStorage") # Concatenate paths
setwd(dataDir)
getwd()
#create a list of the files from your target directory
file_list <- list.files(path=dataDir)
# Load dataset (for loop to load everything)
VM <- read.csv(file = file_list[31], header = TRUE, sep = ";")
# Selecting relevant variables
VM <- VM  %>% select(Timestamp..ms.,CPU.usage....,Memory.usage..KB.,Memory.capacity.provisioned..KB.)
# Memory usage
VM <- VM  %>% mutate(memoryUtilization= 100*Memory.usage..KB./Memory.capacity.provisioned..KB.)
# Rename column
VM <- VM  %>% rename(CPU.utilization= CPU.usage....)
VM <- VM  %>% rename(Timestamp= Timestamp..ms.)
VM <- VM  %>% select(Timestamp,CPU.utilization,memoryUtilization)
# Visualization
# CPU usage
CPU.utilization_df <- data.frame(
day = VM$Timestamp,
value = CPU.utilization
)
# Visualization
# CPU usage
CPU.utilization_df <- data.frame(
day = VM$Timestamp,
value = VM$CPU.utilization
)
p1 <- ggplot(CPU.utilization_df, aes(x=day, y=value)) +
geom_line(color="indianred") +
xlab("Time (ms)") +
ylab("CPU usage (%)")+
theme(axis.text.x=element_blank(),
axis.ticks.x=element_blank()) +
ggtitle("CPU usage")
p1
p2 <- ggplot(memory.usage_df, aes(x=day, y=value)) +
geom_line(color="steelblue") +
xlab("Time (ms)") +
ylab("Memory usage (%)")+
theme(axis.text.x=element_blank(),
axis.ticks.x=element_blank()) +
ggtitle("Memory usage")
# Memory usage
memory.usage_df <- data.frame(
day = VM$Timestamp,
value = VM$memoryUtilization
)
p2 <- ggplot(memory.usage_df, aes(x=day, y=value)) +
geom_line(color="steelblue") +
xlab("Time (ms)") +
ylab("Memory usage (%)")+
theme(axis.text.x=element_blank(),
axis.ticks.x=element_blank()) +
ggtitle("Memory usage")
p2
# CPU utilization
CPU_serie <- ts(VM$CPU.utilization, start =c(1,1), frequency = 1 )
autoplot(CPU_serie)
#Dickey-Fuller test to check stationarity in mean
adf.test(CPU_serie, alternative = "stationary")
# Diff time series
dif1.CPU_serie = diff(CPU_serie)
autoplot(dif1.CPU_serie) +
geom_line(color="indianred") +
xlab("Time (ms)") +
ylab("CPU usage diff")+
theme(axis.text.x=element_blank(),
axis.ticks.x=element_blank()) +
ggtitle("CPU usage diff")
par(mfrow=c(2,1))
# Check ACF and PACF
Acf(dif1.CPU_serie, main="ACF CPU utilization")
Pacf(dif1.CPU_serie,main="PACF CPU utilization")
# Split training and testing for validation
CPU_serie_train <- subset(CPU_serie, start=1, end = length(CPU_serie)-100)
autoplot(CPU_serie_train)
CPU_serie_test <- subset(CPU_serie, start=length(CPU_serie)-100)
# Source: https://otexts.com/fpp2/arima-r.html
auto.arima(CPU_serie, trace=TRUE)
# Fit ARIMA model
fit1_CPU<- Arima(CPU_serie_train, order = c(1,1,2), method=(c("ML")))
summary(fit1_CPU)
residFIT1<-residuals(fit1_CPU)
Acf(residFIT1, main="ACF Residuals CPU utilization")
Pacf(residFIT1, main="PACF Residuals CPU utilization")
#Compute forecasts with model named as fit1
fcast1_CPU <- forecast(fit1_CPU, h=100)
autoplot(fcast1_CPU)
# Model diagnosis
tsdiag(fit1_CPU) #gr?ficos de residuos y Ljung-Box gr?fico
diagnosis1<-checkresiduals(fit1_CPU)
# Check outliers
# Source: https://robjhyndman.com/hyndsight/tsoutliers/
tsoutliers(CPU_serie)
# Replace outlier for interpolated values
autoplot(tsclean(CPU_serie), series="clean", color='red', lwd=0.9) +
autolayer(CPU_serie, series="original", color='gray', lwd=1) +
geom_point(data = tsoutliers(CPU_serie) %>% as.data.frame(),
aes(x=index, y=replacements), col='blue') +
labs(x = "Time (ms)", y = "CPU usage (%)") +
ggtitle("CPU usage - Outlier detection")
# Memory utilization
memory_serie <- ts(VM$memoryUtilization, start =c(1,1), frequency = 1 )
autoplot(memory_serie)
#Dickey-Fuller test to check stationarity in mean
adf.test(memory_serie, alternative = "stationary")
# Check ACF and PACF
Acf(memory_serie, main="ACF Memory utilization")
Pacf(memory_serie,main="PACF Memory utilization")
# Split training and testing for validation
memory_serie_train <- subset(memory_serie, start=1, end = length(memory_serie)-100)
autoplot(memory_serie_train)
memory_serie_test <- subset(memory_serie, start=length(memory_serie)-100)
# Source: https://otexts.com/fpp2/arima-r.html
auto.arima(memory_serie_train, trace=TRUE)
# Fit ARIMA model
fit1_memory<- Arima(memory_serie_train, order = c(2,0,1), method=(c("ML")))
summary(fit1_memory)
residFIT1<-residuals(fit1_memory)
Acf(residFIT1, main="ACF Residuals memory utilization")
Pacf(residFIT1, main="ACF Residuals memory utilization")
#Compute forecasts with model named as fit1
fcast1_memory <- forecast(fit1_memory, h=100)
autoplot(fcast1_memory)
# Model diagnosis
tsdiag(fit1_memory) #gr?ficos de residuos y Ljung-Box gr?fico
diagnosis1<-checkresiduals(fit1_memory)
hopkins_CPU <- hopkins (VM[,1:2], n=nrow(VM)-1)
rm(list = ls()) # Remove all the objects we created so far.
set.seed(123)
#Libraries
library("rstudioapi")
library(dplyr) # Manipulate data
library(ggplot2) # Plots
library(tseries) # Time series
library(mclust) # Clustering
library (NbClust)
library (cluster)
library (clustertend)
library (factoextra)
# Set working directory
curDir <- dirname(getActiveDocumentContext()$path)# Current directory
dataDir <- file.path(curDir,"fastStorage") # Concatenate paths
setwd(dataDir)
getwd()
#create a list of the files from your target directory
file_list <- list.files(path=dataDir)
# Load dataset (for loop to load everything)
VM <- read.csv(file = file_list[31], header = TRUE, sep = ";")
# Selecting relevant variables
VM <- VM  %>% select(Timestamp..ms.,CPU.usage....,Memory.usage..KB.,Memory.capacity.provisioned..KB.)
# Memory usage
VM <- VM  %>% mutate(memoryUtilization= 100*Memory.usage..KB./Memory.capacity.provisioned..KB.)
# Rename column
VM <- VM  %>% rename(CPU.utilization= CPU.usage....)
VM <- VM  %>% rename(Timestamp= Timestamp..ms.)
VM <- VM  %>% select(Timestamp,CPU.utilization,memoryUtilization)
# Visualization
# CPU usage
CPU.utilization_df <- data.frame(
day = VM$Timestamp,
value = VM$CPU.utilization
)
p1 <- ggplot(CPU.utilization_df, aes(x=day, y=value)) +
geom_line(color="indianred") +
xlab("Time (ms)") +
ylab("CPU usage (%)")+
theme(axis.text.x=element_blank(),
axis.ticks.x=element_blank()) +
ggtitle("CPU usage")
rm(list = ls()) # Remove all the objects we created so far.
set.seed(123)
#Libraries
library("rstudioapi")
library(dplyr) # Manipulate data
library(ggplot2) # Plots
library(forecast) # Time series
library(tseries) # Time series
library(mclust) # Clustering
library (NbClust)
library (cluster)
library (clustertend)
library (factoextra)
